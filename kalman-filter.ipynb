{"metadata":{"kernelspec":{"display_name":"Python 3.8.11 64-bit ('sdia-python': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"interpreter":{"hash":"8ced0699d32d8e6de29d5369718307d99fab179af6891fd9441585b0b827fbd5"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"c5a1a266-6831-4ff7-ad6c-1bfc65994098","cell_type":"markdown","source":"## Mohamed Ben ALI","metadata":{}},{"id":"772d94a9-1096-4dde-a3c1-3a8b7a91c2db","cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nimport time","metadata":{},"outputs":[],"execution_count":null},{"id":"55b75d3f","cell_type":"code","source":"C = 1 # constante à déterminer\nQ = 1e-2 # covariance du bruit d'état\nR = 10 # covariance du bruit de mesure","metadata":{},"outputs":[],"execution_count":null},{"id":"c85de0b2","cell_type":"code","source":"z = norm.rvs(loc = C, scale = np.sqrt(R), size = 500) # prend 500 valeurs aléatoires centrées en C et de variance R\nt = np.arange(0, len(z), 1)\nplt.plot(t, z, 'bo')\nplt.title('Les mesures')\nplt.xlabel('Temps (s)')\nplt.ylabel('Les valeurs de la mesures')\nplt.grid()\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"000dd50c","cell_type":"code","source":"xh = np.zeros(shape = len(z)) # vecteur des estimations\nx0 = norm.rvs(loc = 0, scale = np.sqrt(2), size = 1) # condition initiale sur x\nP = np.zeros(shape = len(z)) # vecteur des variances des erreurs d'estimation\nP0 = 1 # condition initiale sur P\n\nxh[0] = x0\nP[0] = P0 + Q # on ajoute le bruit d'état","metadata":{},"outputs":[],"execution_count":null},{"id":"34e40185","cell_type":"code","source":"# Algorithme de Kalman\nfor p in range(0, len(z), 1):\n    K = P[p] / (P[p] + R) # calcul du gain de Kalman\n    xh[p] = xh[p] + K * (z[p] - xh[p]) # estimation\n    P[p] = P[p] - K * P[p] # variance de l'erreur d'estimation\n    if p < len(z) - 1: # passage à l'itération suivante\n        xh[p + 1] = xh[p]\n        P[p + 1] = P[p] + Q","metadata":{},"outputs":[],"execution_count":null},{"id":"d683a11b","cell_type":"code","source":"un = np.ones(shape = len(z))\nplt.plot(t, z, 'go', label = 'Les mesures')\nplt.plot(t, xh, 'r+', label = 'L\\'estimation')\nplt.plot(t, un, 'b', label = 'La valeur de la constante')\nplt.title('Estimation de la constante C')\nplt.xlabel('Temps (s)')\nplt.ylabel('Les valeurs l\\'etimation')\nplt.legend()\nplt.grid()\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"7321c6f4","cell_type":"code","source":"plt.plot(t, P)\nplt.title('evolution de la matrice de covariance')\nplt.xlabel('Temps (s)')\nplt.ylabel('Valeurs de la matrice de covariance')\nplt.grid()\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"99c1555c","cell_type":"code","source":"plt.plot(t, un - xh, 'ys')\nplt.title('Erreur d\\'estimation')\nplt.xlabel('Temps (s)')\nplt.ylabel('Valeurs de l\\'erreur')\nplt.grid()\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"f69161ee-fcbb-4308-8b15-0b2565fb82c8","cell_type":"markdown","source":"## Test de différentes valeurs de Q","metadata":{}},{"id":"09df8621-d2e5-4127-8ef5-48423e1b0b34","cell_type":"code","source":"def kalman(Q) :\n    xh = np.zeros(shape = len(z)) # vecteur des estimations\n    x0 = norm.rvs(loc = 0, scale = np.sqrt(2), size = 1) # condition initiale sur x\n    P = np.zeros(shape = len(z)) # vecteur des variances des erreurs d'estimation\n    P0 = 1 # condition initiale sur P\n\n    xh[0] = x0\n    P[0] = P0 + Q # on ajoute le bruit d'état\n    \n    # Algorithme de Kalman\n    for p in range(0, len(z), 1):\n        K = P[p] / (P[p] + R) # calcul du gain de Kalman\n        xh[p] = xh[p] + K * (z[p] - xh[p]) # estimation\n        P[p] = P[p] - K * P[p] # variance de l'erreur d'estimation\n        if p < len(z) - 1: # passage à l'itération suivante\n            xh[p + 1] = xh[p]\n            P[p + 1] = P[p] + Q\n     \n     \n    plt.figure(figsize=(30,10))       \n    plt.subplot(131)\n    un = np.ones(shape = len(z))\n    plt.plot(t, z, 'go', label = 'Les mesures')\n    plt.plot(t, xh, 'r+', label = 'L\\'estimation')\n    plt.plot(t, un, 'b', label = 'La valeur de la constante')\n    plt.title(f'Estimation de la constante C pour Q = {Q}')\n    plt.xlabel('Temps (s)')\n    plt.ylabel('Les valeurs l\\'etimation')\n    plt.legend()\n    plt.grid()\n    \n    plt.subplot(132)\n    plt.plot(t, P)\n    plt.title(f'Evolution de la matrice de covariance pour Q = {Q}')\n    plt.xlabel('Temps (s)')\n    plt.ylabel('Valeurs de la matrice de covariance')\n    plt.grid()\n    \n    plt.subplot(133)\n    plt.plot(t, un - xh, 'ys')\n    plt.title(f'Erreur d\\'estimation pour Q = {Q}')\n    plt.xlabel('Temps (s)')\n    plt.ylabel('Valeurs de l\\'erreur')\n    plt.grid()\n    plt.show()\n        ","metadata":{},"outputs":[],"execution_count":null},{"id":"41b65fbe","cell_type":"code","source":"Q_list = [10**(k) for k in range(-15,5)]\nQ_list.insert(0,0)\n\nfor Q in Q_list :\n    print(f\"Estimation for Q = {Q}\")\n    kalman(Q)","metadata":{},"outputs":[],"execution_count":null},{"id":"d0c612c6-4ba8-440b-b337-cea83b165ae3","cell_type":"markdown","source":"## Commentaire : effet de la valeur de Q\n\n* On observe que quand Q est \"petit\", le filtre de Kalman a un temps de réponse important mais il n'oscille pas beaucoup autour de la valeur limite : on a donc une erreur résiduelle assez faible (de l'ordre de $10^{-1}$).\n* A l'inverse, quand Q est \"grand\", le filtre de Kalman a un temps de réponse faible (i.e. il se rapproche de la constante à estimer assez rapidement), mais il oscille beaucoup autour de la valeur limite : on a donc une erreur résiduelle importante et variable.\n* On peut s'intéresser au cas limite \"Q tend vers $+\\infty$\". On observe que lorsque Q est très grand, l'estimation devient la mesure elle-même. Cela s'explique par le fait que quand Q tend vers $+\\infty$, le gain de Kalman tend vers 1 et à chaque itération on se contente de donner à l'estimation la valeur de la mesure (`xh[p] = xh[p] + K * (z[p] - xh[p])` dans l'algorithme de Kalman).\n\nEn conclusion, la valeur de Q, le bruit d'état, représente les phénomènes que l'on n'a pas pris en compte dans notre modèle. Sa valeur dépend donc de la \"confiance\" que l'on a dans notre modélisation. Ainsi, si on prend Q très grand, cela signifie que l'on a peu confiance dans notre modèle et on se base uniquement sur les mesures (ce qui explique le cas extrême \"Q tend vers $+\\infty$\"). \n\nDe façon générale, le choix de Q influence le comportement dynamique du filtre de Kalman (rapidité de convergence et précision).","metadata":{}},{"id":"2a024c82-9184-449a-adef-e64138516fdd","cell_type":"markdown","source":"## Estimation d'un signal carré","metadata":{}},{"id":"adae4a64-f503-46e6-9790-f1e5c144c9e7","cell_type":"code","source":"C = 1 # constante à déterminer\nQ = 1e-2 # covariance du bruit d'état\nR = 0.1 # covariance du bruit de mesure\n\n# Signal carré à estimer\nx = np.zeros(shape = 100)\nfor _ in range(0,3):\n    x_up = np.ones(shape = 100)\n    x_down = np.zeros(shape = 100)\n    x = np.hstack((x,x_up,x_down)) \n\n# Génération de points aléatoires\nz = norm.rvs(loc = 0, scale = np.sqrt(R), size = 100) \nfor _ in range(0,3):\n    z1 = norm.rvs(loc = C, scale = np.sqrt(R), size = 100) \n    z0 = norm.rvs(loc = 0, scale = np.sqrt(R), size = 100)\n    z = np.hstack((z,z1,z0)) \n    \n \nt = np.arange(0, len(z), 1)\nplt.plot(t, z, 'bo')\nplt.plot(t, x, 'r')\nplt.title('Les mesures et le signal carré')\nplt.xlabel('Temps (s)')\nplt.ylabel('Les valeurs de la mesures')\nplt.grid()\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"4f2f0d4d-1f18-42c4-918d-cabc55c5c48a","cell_type":"code","source":"def kalman_square(Q):\n    xh = np.zeros(shape = len(z)) # vecteur des estimations\n    x0 = norm.rvs(loc = 0, scale = np.sqrt(2), size = 1) # condition initiale sur x\n    P = np.zeros(shape = len(z)) # vecteur des variances des erreurs d'estimation\n    P0 = 1 # condition initiale sur P\n\n    xh[0] = x0\n    P[0] = P0 + Q # on ajoute le bruit d'état\n    \n    # Algorithme de Kalman\n    for p in range(0, len(z), 1):\n        K = P[p] / (P[p] + R) # calcul du gain de Kalman\n        xh[p] = xh[p] + K * (z[p] - xh[p]) # estimation\n        P[p] = P[p] - K * P[p] # variance de l'erreur d'estimation\n        if p < len(z) - 1: # passage à l'itération suivante\n            xh[p + 1] = xh[p]\n            P[p + 1] = P[p] + Q\n     \n     \n    plt.figure(figsize=(30,10))       \n    plt.subplot(131)\n    un = np.ones(shape = len(z))\n    plt.plot(t, z, 'go', label = 'Les mesures')\n    plt.plot(t, xh, 'r+', label = 'L\\'estimation')\n    plt.plot(t, x, 'b', label = 'La valeur de la constante')\n    plt.title(f'Estimation de la constante C pour Q = {Q}')\n    plt.xlabel('Temps (s)')\n    plt.ylabel('Les valeurs l\\'etimation')\n    plt.legend()\n    plt.grid()\n    \n    plt.subplot(132)\n    plt.plot(t, P)\n    plt.title(f'Evolution de la matrice de covariance pour Q = {Q}')\n    plt.xlabel('Temps (s)')\n    plt.ylabel('Valeurs de la matrice de covariance')\n    plt.grid()\n    \n    plt.subplot(133)\n    plt.plot(t, un - xh, 'ys')\n    plt.title(f'Erreur d\\'estimation pour Q = {Q}')\n    plt.xlabel('Temps (s)')\n    plt.ylabel('Valeurs de l\\'erreur')\n    plt.grid()\n    plt.show()\n    ","metadata":{},"outputs":[],"execution_count":null},{"id":"eb92edfa-20df-4a2f-8a48-9ec3c7a5a8a6","cell_type":"code","source":"Q_list = [10**(k) for k in range(-15,5)]\nQ_list.insert(0,0)\n\nfor Q in Q_list :\n    print(f\"Estimation for Q = {Q}\")\n    kalman_square(Q)","metadata":{},"outputs":[],"execution_count":null},{"id":"2f01f2dd-9e63-441e-bea6-d67e930e3ebf","cell_type":"markdown","source":"## Commentaire : estimation d'un signal carré\n\nEncore une fois, on essaie différentes valeurs de Q pour estimer le signal carré x. On peut noter que l'on a réduit le bruit de mesure R car la valeur de 10 était beaucoup trop grande pour un signal variant entre 0 et 1 (il serait noyé dans le bruit).\n\nOn fait alors les observations suivantes :\n\n* Tout ce qui a été dit précédemment sur l'influence de Q est encore valable.\n* Ce qui est remarquable ici est que quand Q est petit, le temps de réponse est trop faible pour que l'estimation puisse s'approcher du signal sur chacun des intervalles (\"le filtre n'a pas le temps d'estimer la constante 1 avant qu'elle devienne 0 et inversement\").\n* Pour Q grand, le temps de réponse est suffisant pour se rapprocher du signal carré réel mais les oscillations deviennent alors très importantes.","metadata":{}},{"id":"fce57d19-5b94-4f63-8a96-e8db2c50f002","cell_type":"markdown","source":"## Peut-on mieux estimer le signal carré si R est \"petit\" ?","metadata":{}},{"id":"0468a8d5-3dbb-4cec-85d5-562905d1d8f6","cell_type":"code","source":"C = 1 # constante à déterminer\nQ = 1e-2 # covariance du bruit d'état\nR = 0.001 # covariance du bruit de mesure --> on la diminue !\n\n# Signal carré à estimer\nx = np.zeros(shape = 100)\nfor _ in range(0,3):\n    x_up = np.ones(shape = 100)\n    x_down = np.zeros(shape = 100)\n    x = np.hstack((x,x_up,x_down)) \n\n# Génération de variable aléatoires\nz = norm.rvs(loc = 0, scale = np.sqrt(R), size = 100) \nfor _ in range(0,3):\n    z1 = norm.rvs(loc = C, scale = np.sqrt(R), size = 100) \n    z0 = norm.rvs(loc = 0, scale = np.sqrt(R), size = 100)\n    z = np.hstack((z,z1,z0)) \n    \n \nt = np.arange(0, len(z), 1)\nplt.plot(t, z, 'bo')\nplt.plot(t, x, 'r')\nplt.title('Les mesures et le signal carré')\nplt.xlabel('Temps (s)')\nplt.ylabel('Les valeurs de la mesures')\nplt.grid()\nplt.show()\n\nQ_list = [10**(k) for k in range(-15,5)]\nQ_list.insert(0,0)\n\nfor Q in Q_list :\n    print(f\"Estimation for Q = {Q}\")\n    kalman_square(Q)","metadata":{},"outputs":[],"execution_count":null},{"id":"4eeb731a-cc06-4331-8a96-b205a5528e2e","cell_type":"markdown","source":"## Commentaire\n\nOn remarque que cette fois, pour un bon choix de Q (e.g. Q = 1e-05), on arrive à estimer le signal de façon satisfaisante. En revanche, si Q est petit on n'arrive toujours pas à estimer le signal puisque l'on a encore le problème du temps de réponse trop faible du filtre.","metadata":{}}]}